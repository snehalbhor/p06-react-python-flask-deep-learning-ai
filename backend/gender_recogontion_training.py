# -*- coding: utf-8 -*-
"""Gender_Recogontion_Training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18BYAaADgmVzhF1eG8xjzk0S0Y2O8jlOd
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/darknet

!unzip /content/drive/MyDrive/training_data.zip

!git clone https://github.com/AlexeyAB/darknet

# Commented out IPython magic to ensure Python compatibility.
# change makefile to have GPU and OPENCV enabled
# also set CUDNN, CUDNN_HALF and LIBSO to 1

# %cd /content/darknet/
!sed -i 's/OPENCV=0/OPENCV=1/' Makefile
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile
!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile
!sed -i 's/LIBSO=0/LIBSO=1/' Makefile

!make

pwd

!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights
!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29

# Commented out IPython magic to ensure Python compatibility.
#Copy dataset
# %cp -r /content/darknet/training_data/. /content/darknet/
#Set up training file directories for custom dataset
# %cd /content/darknet/
# %cp train/_darknet.labels data/obj.names
# %mkdir data/obj
#copy image and labels
# %cp train/*.jpg data/obj/
# %cp test/*.jpg data/obj/

# %cp train/*.txt data/obj/
# %cp test/*.txt data/obj/

with open('data/obj.data', 'w') as out:
  out.write('classes = 3\n')
  out.write('train = data/train.txt\n')
  out.write('test = data/test.txt\n')
  out.write('names = data/obj.names\n')
  out.write('backup = backup/')

#write train file (just the image list)
import os

with open('data/train.txt', 'w') as out:
  for img in [f for f in os.listdir('train') if f.endswith('jpg')]:
    out.write('data/obj/' + img + '\n')

#write the valid file (just the image list)
import os

with open('data/test.txt', 'w') as out:
  for img in [f for f in os.listdir('test') if f.endswith('jpg')]:
    out.write('data/obj/' + img + '\n')

#we build config dynamically based on number of classes
#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg
def file_len(fname):
  with open(fname) as f:
    for i, l in enumerate(f):
      pass
  return i + 1

num_classes = file_len('train/_darknet.labels')
print("Total number of classes are :",num_classes)
max_batches = num_classes*2000
steps1 = .8 * max_batches
steps2 = .9 * max_batches
steps_str = str(steps1)+','+str(steps2)
num_filters = (num_classes + 5) * 3


print("writing config for a custom YOLOv4 detector detecting number of classes: " + str(num_classes))

#Instructions from the darknet repo
#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes
#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400
if os.path.exists('./cfg/custom-yolov4-tiny-detector.cfg'): os.remove('./cfg/custom-yolov4-tiny-detector.cfg')


#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))

# Commented out IPython magic to ensure Python compatibility.
# %%writetemplate ./cfg/custom-yolov4-tiny-detector.cfg
# [net]
# # Testing
# #batch=1
# #subdivisions=1
# # Training
# batch=64
# subdivisions=16
# width=416
# height=416
# channels=3
# momentum=0.9
# decay=0.0005
# angle=0
# saturation = 1.5
# exposure = 1.5
# hue=.1
# 
# learning_rate=0.00261
# burn_in=1000
# max_batches = {max_batches}
# policy=steps
# steps={steps_str}
# scales=.1,.1
# 
# [convolutional]
# batch_normalize=1
# filters=32
# size=3
# stride=2
# pad=1
# activation=leaky
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=3
# stride=2
# pad=1
# activation=leaky
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [route]
# layers=-1
# groups=2
# group_id=1
# 
# [convolutional]
# batch_normalize=1
# filters=32
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [convolutional]
# batch_normalize=1
# filters=32
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [route]
# layers = -1,-2
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=1
# stride=1
# pad=1
# activation=leaky
# 
# [route]
# layers = -6,-1
# 
# [maxpool]
# size=2
# stride=2
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [route]
# layers=-1
# groups=2
# group_id=1
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [route]
# layers = -1,-2
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=leaky
# 
# [route]
# layers = -6,-1
# 
# [maxpool]
# size=2
# stride=2
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [route]
# layers=-1
# groups=2
# group_id=1
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [route]
# layers = -1,-2
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=leaky
# 
# [route]
# layers = -6,-1
# 
# [maxpool]
# size=2
# stride=2
# 
# [convolutional]
# batch_normalize=1
# filters=512
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# ##################################
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=leaky
# 
# [convolutional]
# batch_normalize=1
# filters=512
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [convolutional]
# size=1
# stride=1
# pad=1
# filters={num_filters}
# activation=linear
# 
# 
# 
# [yolo]
# mask = 3,4,5
# anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
# classes={num_classes}
# num=6
# jitter=.3
# scale_x_y = 1.05
# cls_normalizer=1.0
# iou_normalizer=0.07
# iou_loss=ciou
# ignore_thresh = .7
# truth_thresh = 1
# random=0
# nms_kind=greedynms
# beta_nms=0.6
# 
# [route]
# layers = -4
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=leaky
# 
# [upsample]
# stride=2
# 
# [route]
# layers = -1, 23
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=3
# stride=1
# pad=1
# activation=leaky
# 
# [convolutional]
# size=1
# stride=1
# pad=1
# filters={num_filters}
# activation=linear
# 
# [yolo]
# mask = 1,2,3
# anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
# classes={num_classes}
# num=6
# jitter=.3
# scale_x_y = 1.05
# cls_normalizer=1.0
# iou_normalizer=0.07
# iou_loss=ciou
# ignore_thresh = .7
# truth_thresh = 1
# random=0
# nms_kind=greedynms
# beta_nms=0.6

# Commented out IPython magic to ensure Python compatibility.
#here is the file that was just written.
#you may consider adjusting certain things

#like the number of subdivisions 64 runs faster but Colab GPU may not be big enough
#if Colab GPU memory is too small, you will need to adjust subdivisions to 16
# %cat cfg/custom-yolov4-tiny-detector.cfg

pwd

!./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg yolov4-tiny.conv.29 -dont_show -map

!./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg yolov4-tiny.conv.29 -dont_show -map

# Commented out IPython magic to ensure Python compatibility.
# define helper function imShow
def imShow(path):
  import cv2
  import matplotlib.pyplot as plt
#   %matplotlib inline

  image = cv2.imread(path)
  height, width = image.shape[:2]
  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)

  fig = plt.gcf()
  fig.set_size_inches(18, 10)
  plt.axis("off")
  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))
  #plt.show('')

!./darknet detector test data/obj.data cfg/custom-yolov4-tiny-detector.cfg /content/darknet/backup/custom-yolov4-tiny-detector_best.weights /content/darknet/test/test.jpg -thresh 0.3
imShow('predictions.jpg')